{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "#import gym\n",
    "#import cv2\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from IPython import display\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FRAMES = 4\n",
    "\n",
    "def filter(obs):\n",
    "    assert(type(obs) == np.ndarray), \"The observation must be a numpy array!\"\n",
    "\n",
    "    m = np.mean(obs)\n",
    "    v = np.var(obs)\n",
    "    \n",
    "    obs = (obs - m)/v   \n",
    "    return obs\n",
    "\n",
    "def get_stacked_obs(obs, prev_frames):\n",
    "    if not prev_frames:\n",
    "        prev_frames = [obs] * (N_FRAMES - 1)\n",
    "        \n",
    "    prev_frames.append(obs)\n",
    "    stacked_frames = np.stack(prev_frames)\n",
    "    prev_frames = prev_frames[-(N_FRAMES-1):]\n",
    "    \n",
    "    return stacked_frames, prev_frames\n",
    "\n",
    "def preprocess_obs(obs, prev_frames):\n",
    "    filtered_obs = filter(obs)\n",
    "    stacked_obs, prev_frames = get_stacked_obs(filtered_obs, prev_frames)\n",
    "    return stacked_obs, prev_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Paper\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, len_state, len_action):\n",
    "        \n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(len_state+len_action,64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(64,1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, obs):\n",
    "        q_values = self.layer1(obs)\n",
    "        q_values = self.layer2(q_values)\n",
    "        q_values = self.layer3(q_values)\n",
    "        \n",
    "        return q_values\n",
    "    \n",
    "    def train_on_batch(self, target_model, optimizer,input, obs, acts, rewards, next_obs, terminals, gamma=0.99):\n",
    "\n",
    "        #тут пока не сделано \n",
    "        \n",
    "        sampler = qmc.LatinHypercube(d=X.shape[1])\n",
    "        sample = sampler.random(n=5)\n",
    "        sample_scaled = qmc.scale(sample, l_bounds, u_bounds)\n",
    "        actions = np.array(sample_scaled)\n",
    "        next_q_values = []\n",
    "        for a in actions:\n",
    "            input = torch.tensor(np.concatenate((next_obs,[a]*4),axis=1)).float() \n",
    "            q_value = self.forward(next_obs)\n",
    "            #q_value = q_value.detach().numpy()\n",
    "            next_q_values.append(q_value)\n",
    "        \n",
    "        #next_q_values = self.forward(next_obs)\n",
    "        max_next_acts = torch.max(next_q_values, dim=1)[1].detach()\n",
    "        \n",
    "        target_next_q_values = target_model.forward(next_obs)\n",
    "        max_next_q_values = target_next_q_values.gather(index=max_next_acts.view(-1, 1), dim=1)\n",
    "        max_next_q_values = max_next_q_values.view(-1).detach()\n",
    "        \n",
    "        terminal_mods = 1 - terminals\n",
    "        actual_qs = rewards + terminal_mods * gamma * max_next_q_values\n",
    "            \n",
    "        pred_qs = self.forward(obs)\n",
    "        pred_qs = pred_qs.gather(index=acts.view(-1, 1), dim=1).view(-1)\n",
    "        \n",
    "        loss = torch.mean((actual_qs - pred_qs) ** 2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.data = []\n",
    "        \n",
    "    def add_step(self, step_data):\n",
    "        self.data.append(step_data)\n",
    "        if len(self.data) > self.capacity:\n",
    "            self.data = self.data[-self.capacity:]\n",
    "            \n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.data))\n",
    "        indices = np.random.choice(range(len(self.data)), n, replace=False)\n",
    "        samples = np.asarray(self.data, dtype=\"object\")[indices]\n",
    "\n",
    "        #print(samples[:, 0],list(samples[:, 1])*4)\n",
    "        input = torch.tensor(np.concatenate((samples[:, 0][0],list(samples[:, 1])*4),axis=1)).float() \n",
    "        #print(input)\n",
    "        \n",
    "        state_data = torch.tensor(np.stack(samples[:, 0])).float()\n",
    "        act_data = torch.tensor(np.stack(samples[:, 1])).float()\n",
    "        reward_data = torch.tensor(np.stack(samples[:, 2])).float()\n",
    "        next_state_data = torch.tensor(np.stack(samples[:, 3])).float()\n",
    "        terminal_data = torch.tensor(np.stack(samples[:, 4])).int()\n",
    "        \n",
    "        return input, state_data, act_data, reward_data, next_state_data, terminal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Algorithm\n",
    "\n",
    "<img src='imgs/dqn_algorithm.png' width=80% align='left' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "from scipy.stats import qmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<model.NN.NN_model object at 0x16cd91160>\n"
     ]
    }
   ],
   "source": [
    "X = np.linspace(-3,3,90).reshape(-1,3)\n",
    "y = np.sum(np.sin(X),axis=1)\n",
    "\n",
    "def f(x):\n",
    "    s = np.sin(x).shape\n",
    "    if len(s)>1:\n",
    "        return np.sum(np.sin(x),axis=1)\n",
    "    else:\n",
    "        return [np.sum(np.sin(x))]\n",
    "\n",
    "l_bounds = [-3,-3,-3]\n",
    "u_bounds = [3,3,3]\n",
    "\n",
    "env = Environment(X = X,y = y,l_bounds = l_bounds,u_bounds = u_bounds, func = f, model = 'NN',model_param = {'d':3,'nb_nodes':40,'nb_layers':4})\n",
    "\n",
    "state = env.Reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_episodes = 10000\n",
    "n_episodes = 100\n",
    "max_steps = 100\n",
    "er_capacity = 15 # 1m in paper\n",
    "#n_acts = env.action_space.n # 0: no-op, 1: start game, 2: right, 3: left\n",
    "train_batch_size = 32\n",
    "learning_rate = 2.5e-4\n",
    "update_freq = 4\n",
    "print_freq = 5\n",
    "frame_skip = 3\n",
    "n_anneal_steps = 1e5 # Anneal over 1m steps in paper\n",
    "target_update_delay = 10 # How many timesteps in between target model update\n",
    "epsilon = lambda step: np.clip(1 - 0.9 * (step/n_anneal_steps), 0.1, 1) # Anneal over 1m steps in paper, 100k here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98165751 -2.74413576 -1.45612695]\n",
      "[-0.99324214 -0.10862727 -2.26533127 ...  0.98165751 -2.74413576\n",
      " -1.45612695]\n",
      "[array([[-0.60470466, -1.09326215, -1.31471361, ...,  1.68070455,\n",
      "          1.72014803,  1.7595915 ],\n",
      "        [-0.60470466, -1.09326215, -1.31471361, ...,  1.68070455,\n",
      "          1.72014803,  1.7595915 ],\n",
      "        [-0.60470466, -1.09326215, -1.31471361, ...,  1.68070455,\n",
      "          1.72014803,  1.7595915 ],\n",
      "        [-0.60470466, -1.09326215, -1.31471361, ...,  1.68070455,\n",
      "          1.72014803,  1.7595915 ]])                             ] [array([ 0.98165751, -2.74413576, -1.45612695]), array([ 0.98165751, -2.74413576, -1.45612695]), array([ 0.98165751, -2.74413576, -1.45612695]), array([ 0.98165751, -2.74413576, -1.45612695])]\n",
      "tensor([[-0.6047, -1.0933, -1.3147,  ...,  0.9817, -2.7441, -1.4561],\n",
      "        [-0.6047, -1.0933, -1.3147,  ...,  0.9817, -2.7441, -1.4561],\n",
      "        [-0.6047, -1.0933, -1.3147,  ...,  0.9817, -2.7441, -1.4561],\n",
      "        [-0.6047, -1.0933, -1.3147,  ...,  0.9817, -2.7441, -1.4561]])\n",
      "tensor([[[-0.6047, -1.0933, -1.3147,  ...,  1.6807,  1.7201,  1.7596],\n",
      "         [-0.6047, -1.0933, -1.3147,  ...,  1.6807,  1.7201,  1.7596],\n",
      "         [-0.6047, -1.0933, -1.3147,  ...,  1.6807,  1.7201,  1.7596],\n",
      "         [-0.6047, -1.0933, -1.3147,  ...,  1.6807,  1.7201,  1.7596]]]) tensor([[ 0.9817, -2.7441, -1.4561]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x1030 and 1033x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m     obs_data, act_data, reward_data, next_obs_data, terminal_data \u001b[38;5;241m=\u001b[39m er\u001b[38;5;241m.\u001b[39msample(train_batch_size)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(obs_data, act_data)\n\u001b[0;32m---> 59\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain_on_batch(target_model, optimizer, obs_data, act_data,\n\u001b[1;32m     60\u001b[0m                          reward_data, next_obs_data, terminal_data)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m### Update target network ###\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;129;01mand\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m target_update_delay \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mDQN.train_on_batch\u001b[0;34m(self, target_model, optimizer, obs, acts, rewards, next_obs, terminals, gamma)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_on_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, target_model, optimizer, obs, acts, rewards, next_obs, terminals, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m):\n\u001b[0;32m---> 25\u001b[0m     next_q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(next_obs)\n\u001b[1;32m     26\u001b[0m     max_next_acts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(next_q_values, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     28\u001b[0m     target_next_q_values \u001b[38;5;241m=\u001b[39m target_model\u001b[38;5;241m.\u001b[39mforward(next_obs)\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mDQN.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[0;32m---> 18\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(obs)\n\u001b[1;32m     19\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(q_values)\n\u001b[1;32m     20\u001b[0m     q_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(q_values)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x1030 and 1033x64)"
     ]
    }
   ],
   "source": [
    "er = ExperienceReplay(er_capacity)\n",
    "model = DQN(len(state),X.shape[1])\n",
    "\n",
    "target_model = copy.deepcopy(model)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, eps=1e-6)\n",
    "all_rewards = []\n",
    "global_step = 0\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    prev_frames = []\n",
    "    obs, prev_frames = preprocess_obs(env.Reset(), prev_frames)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "    while step < max_steps:\n",
    "\n",
    "        ### Enact a step ###\n",
    "        if np.random.rand() < epsilon(global_step):\n",
    "            sampler = qmc.LatinHypercube(d=X.shape[1])\n",
    "            sample = sampler.random(n=1)\n",
    "            sample_scaled = qmc.scale(sample, l_bounds, u_bounds)\n",
    "            act = np.array(sample_scaled)[0]\n",
    "            #act = np.random.choice(range(n_acts))\n",
    "        else:   \n",
    "            sampler = qmc.LatinHypercube(d=X.shape[1])\n",
    "            sample = sampler.random(n=5)\n",
    "            sample_scaled = qmc.scale(sample, l_bounds, u_bounds)\n",
    "            acts = np.array(sample_scaled)\n",
    "            q_values = []\n",
    "            for a in acts:\n",
    "                input = torch.tensor(np.concatenate((obs,[a]*4),axis=1)).float() \n",
    "                q_value = model(input)[0]\n",
    "                q_value = q_value.detach().numpy()\n",
    "                q_values.append(q_value)\n",
    "                \n",
    "            act = acts[np.argmax(q_values)]\n",
    "        print(act)\n",
    "        \n",
    "        cumulative_reward = 0\n",
    "        for _ in range(frame_skip):\n",
    "            next_obs, reward, done, _ = env.Step(act)\n",
    "            cumulative_reward += reward\n",
    "            current_reward = reward\n",
    "            if done or step >= max_steps:\n",
    "                break\n",
    "        #episode_reward += cumulative_reward\n",
    "        #reward = format_reward(cumulative_reward)\n",
    "        reward = current_reward\n",
    "\n",
    "        next_obs, prev_frames = preprocess_obs(next_obs, prev_frames)\n",
    "        er.add_step([obs, act, reward, next_obs, int(done)])\n",
    "        obs = next_obs\n",
    "        \n",
    "        ### Train on a minibatch ###\n",
    "        \n",
    "        if global_step % update_freq == 0:\n",
    "            input, obs_data, act_data, reward_data, next_obs_data, terminal_data = er.sample(train_batch_size)\n",
    "            #print(obs_data, act_data)\n",
    "            model.train_on_batch(target_model, optimizer, input, obs_data, act_data,\n",
    "                                 reward_data, next_obs_data, terminal_data)\n",
    "        \n",
    "        ### Update target network ###\n",
    "        \n",
    "        if global_step and global_step % target_update_delay == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "        \n",
    "        ### Finish the step ###\n",
    "        \n",
    "        step += 1\n",
    "        global_step += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    all_rewards.append(episode_reward)\n",
    "    \n",
    "    if episode % print_freq == 0:\n",
    "        print('Episode #{} | Step #{} | Epsilon {:.2f} | Avg. Reward {:.2f}'.format(\n",
    "            episode, global_step, epsilon(global_step), np.mean(all_rewards[-print_freq:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frames = []\n",
    "obs, prev_frames = preprocess_obs(env.reset(), prev_frames)\n",
    "\n",
    "for step in range(max_steps):\n",
    "    if np.random.rand() < 0.05:\n",
    "        act = np.random.choice(range(n_acts))\n",
    "    else:\n",
    "        obs_tensor = torch.tensor([obs]).float().cuda()\n",
    "        q_values = model(obs_tensor)[0]\n",
    "        q_values = q_values.cpu().detach().numpy()\n",
    "        act = np.argmax(q_values)\n",
    "\n",
    "    for _ in range(frame_skip):\n",
    "        next_obs, reward, done, _ = env.step(act)\n",
    "        if done or step >= max_steps:\n",
    "            break\n",
    "            \n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    obs, prev_frames = preprocess_obs(next_obs, prev_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb38b2ef50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoothed_rewards = []\n",
    "smooth_window = 1\n",
    "for i in range(smooth_window, len(all_rewards)-smooth_window):\n",
    "    smoothed_rewards.append(np.mean(all_rewards[i-smooth_window:i+smooth_window]))\n",
    "    \n",
    "plt.plot(range(len(smoothed_rewards)), smoothed_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/double_dqn_breakout_r14.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
